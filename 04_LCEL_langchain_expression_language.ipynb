{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take the CommaSeparatedListOutputParser example from Day 3 and rebuild it using LCEL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Understanding the Flow (Conceptual) ---\n",
    "1. chain.invoke({\"topic\": \"...\"}) is called.\n",
    "2. The input dictionary {\"topic\": \"...\"} is passed to `prompt_template`.\n",
    "3. `prompt_template` formats the prompt string using the topic and format_instructions.\n",
    "4. The formatted prompt (which is a list of messages for ChatPromptTemplate) is passed to `llm`.\n",
    "5. `llm.invoke()` processes the prompt and returns an AIMessage.\n",
    "6. The AIMessage object is passed to `list_parser`.\n",
    "7. `list_parser.parse()` extracts the `.content` from the AIMessage and parses it.\n",
    "8. The final parsed list is returned by `chain.invoke()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Output Parser\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "format_instruction = list_parser.get_format_instructions()\n",
    "\n",
    "#2. prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"List 5 specific example related to topic : {topic}.\\n {format_instruction}\"\n",
    ")\n",
    "\n",
    "#3. LLM configuration\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "#4. Partial prompt: prefill the format_instruction variable. The resulting partial prompt object only expect the remaining\n",
    "# variable to be filled in i.e. topic\n",
    "partial_prompt = prompt_template.partial(format_instruction=format_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the chain using LCEL\n",
    "# The | operetor is used to chain the components together\n",
    "# The flow is: prompt template -> LLM -> output parser\n",
    "chain = partial_prompt | llm | list_parser\n",
    "\n",
    "print(\"LCEL Chain\")\n",
    "print(chain) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain\n",
    "input_data = {\"topic\": \"popular ai agent frameworks\"}\n",
    "\n",
    "try:\n",
    "    result = chain.invoke(input_data)\n",
    "    print(f\"\\nChain output (passed through parser): {result}\")\n",
    "    print(f\"Type of result: {type(result)}\")\n",
    "\n",
    "    # Lets try another topic\n",
    "    input_data_2 = {\"topic\": \"popular online AIML course which has a good rating\"}\n",
    "    result_2 = chain.invoke(input_data_2)\n",
    "    print(f\"\\nChain output2 (passed through parser): {result_2}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking chain: {e}\")\n",
    "    print(f\"Type of error: {type(e)}\")\n",
    "    print(f\"Error message: {str(e)}\")\n",
    "    if hasattr(e, 'response'):\n",
    "        print(f\"Response: {e.response}\")\n",
    "    if hasattr(e, 'status_code'):\n",
    "        print(f\"Status code: {e.status_code}\")\n",
    "    if hasattr(e, 'headers'):\n",
    "        print(f\"Headers: {e.headers}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
