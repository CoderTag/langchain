{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hands-On: Simple Contextual Q&A Chain\n",
    "\n",
    "Let's build a chain that answers a question based only on a short piece of context provided within the prompt itself. This is a precursor to the RAG pattern we'll learn later, but without external data loading yet.\n",
    "\n",
    "- Task: Create an LCEL chain that:\n",
    "    - Takes two inputs: context (a paragraph of text) and question (a question about the context).\n",
    "\n",
    "Uses a ChatPromptTemplate to instruct the LLM to answer the question using only the provided context. If the answer isn't in the context, it should say so.\n",
    "\n",
    "##### Think about:\n",
    "- How will you define the ChatPromptTemplate to accept both context and question?\n",
    "- What instructions should you give the LLM in the prompt (e.g., a system message)?\n",
    "- How will you structure the LCEL chain using |?\n",
    "- What will the input dictionary look like when you .invoke() the chain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### context_text\n",
    "> The Water Cycle, also known as the hydrologic cycle, describes the continuous movement of water on, above, and below the surface of the Earth.\n",
    "Water evaporates from the surface (like oceans, lakes), rises into the atmosphere, cools and condenses into clouds, and then falls back to the surface as precipitation (rain, snow).\n",
    "Some precipitation flows over the surface as runoff, eventually returning to rivers and oceans, while other water infiltrates the ground.\n",
    "\n",
    "\n",
    "> - question1 = \"What is another name for the Water Cycle?\"\n",
    "> - question2 = \"Where does water evaporate from?\"\n",
    "> -  question3 = \"What happens to water after it infiltrates the ground?\" # Answer slightly less direct\n",
    "> - question4 = \"What is the chemical formula for water?\" # Answer not in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 LLM\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "#2 Prompt Template\n",
    "# Needs 'context' and 'question' variables\n",
    "qa_system_prompt = \"\"\"You are a strict assistant for question-answering tasks.\n",
    "You must answer using only the information provided in the context.\n",
    "You are not allowed to use any external knowledge or make assumptions.\n",
    "If the answer is not present in the context, you must say \"I don't know\".\n",
    "Use at most three sentences maximum and keep the answer concise.\"\"\"\n",
    "\n",
    "qa_human_prompt = \"\"\"Question: {question}\n",
    "Context: {context}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        (\"human\", qa_human_prompt),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#3 Output Parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "#4 LCEL Chain\n",
    "qa_chain = prompt | llm | output_parser\n",
    "\n",
    "# --- Test the Chain ---\n",
    "\n",
    "context_text = \"\"\"\n",
    "The Water Cycle, also known as the hydrologic cycle, describes the continuous movement of water on, above, and below the surface of the Earth.\n",
    "Water evaporates from the surface (like oceans, lakes), rises into the atmosphere, cools and condenses into clouds, and then falls back to the surface as precipitation (rain, snow).\n",
    "Some precipitation flows over the surface as runoff, eventually returning to rivers and oceans, while other water infiltrates the ground.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"What is another name for the Water Cycle?\",\n",
    "    \"Where does water evaporate from according to the text?\",\n",
    "    \"What happens to water after it infiltrates the ground, based on this context?\",\n",
    "    \"What is the chemical formula for water?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the chain with different questions\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    try:\n",
    "        # Prepare input dictionary for chain\n",
    "        input_dict = {\n",
    "            \"context\": context_text,\n",
    "            \"question\": question\n",
    "        }\n",
    "        answer = qa_chain.invoke(input_dict)\n",
    "        print(f\"Answer: {answer}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method-1: Adding a layer to make sure the answer is coming from the context\n",
    "\n",
    "Though is not a very effective solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_answer(context: str, answer: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validate the answer against the context.\n",
    "    Returns True if the answer is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    context_words = set(context.lower().split())\n",
    "    answer_words = set(answer.lower().split())\n",
    "    extra_words = answer_words - context_words\n",
    "\n",
    "    # Allow common filter words, punctiation etc.\n",
    "    allowed_words = {\n",
    "        \"i\", \"don't\", \"know\", \"the\", \"is\", \"a\", \"an\", \"and\", \"of\", \"to\", \"in\",\n",
    "        \"on\", \"for\", \"with\", \"as\", \"by\", \"at\", \",\", \".\", \";\", \"-\", \"_\",\n",
    "        \"yes\", \"no\", \"not\", \"this\", \"that\", \"it\", \"its\", \"there\", \"where\",'aquifers.', 'contribute', 'may',\n",
    "        \"who\", \"which\", \"what\", \"when\", \"how\", \"why\", \"all\", \"any\", \"some\",'lakes.', 'surface,',\n",
    "        \"many\", \"much\", \"more\", \"most\", \"less\", \"least\", \"few\", \"fewer\",'pathways.',\n",
    "        \"none\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\",\n",
    "        \"eight\", \"nine\", \"ten\", \"first\", \"second\", \"third\", \"last\", \"next\",\n",
    "        \"previous\", \"current\", \"future\", \"past\", \"present\", \"future\", \"always\",\n",
    "        \"never\", \"sometimes\", \"often\", \"rarely\", \"seldom\", \"usually\", \"generally\",\n",
    "        \"occasionally\", \"frequently\", \"regularly\", \"periodically\", \"repeatedly\",\n",
    "        \"constantly\", \"continuously\", \"infrequently\", \"sporadically\", \"intermittently\",\n",
    "        \"another\", \"name\", \"cycle\", \"cycle.\",\"such\",\"lakes\",\"oceans\",\"surface\",\n",
    "        \"pathway\", 'way', 'soil', 'can', 'absorbed', 'replenish', 'or', 'ground,', 'sources,', 'make', 'be', \n",
    "        'underground', 'after', 'groundwater', 'plants,', 'through','know.'\n",
    "    }\n",
    "\n",
    "    suspicious_words = extra_words - allowed_words\n",
    "    print(f\"Suspicious words: {suspicious_words}\")\n",
    "    return len(suspicious_words) == 0 and len(answer_words) > 0 and len(answer) > 0\n",
    "    # Check if the answer is in the context\n",
    "    return answer in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    input_dict = {\"context\": context_text, \"question\": question}\n",
    "    answer = qa_chain.invoke(input_dict)\n",
    "    is_valid = validate_answer(context_text, answer)\n",
    "    \n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"✅ Valid Answer\\n\" if is_valid else \"❌ Possibly Hallucinated Answer\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method-2: Adding a layer to make sure the answer is coming from the context\n",
    "#### Chain with Contextual Cross-Check using another LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validator LLM (use same or different model)\n",
    "validator_llm = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=1000,\n",
    ")\n",
    "# Validator Prompt Template\n",
    "validator_system_prompt = \"\"\"You are a strict evaluator.\n",
    "Read the following context and an answer to a question.\n",
    "Decide whether the answer can be fully supported by ONLY the context provided.\n",
    "Answer with \"VALID\" if the answer is fully grounded in the context.\n",
    "Answer with \"INVALID\" if any part of it comes from outside knowledge.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer: {answer}\n",
    "\n",
    "Is this an answer that can be fully supported by the context?\n",
    "Answer with \"VALID\" or \"INVALID\" only.\n",
    "\"\"\"\n",
    "validator_system_prompt = PromptTemplate.from_template(validator_system_prompt)\n",
    "\n",
    "validator_chain = validator_system_prompt | validator_llm | output_parser\n",
    "\n",
    "def qa_with_validation(context: str, question: str) -> dict:\n",
    "    input_dict = {\"context\": context, \"question\": question}\n",
    "    answer = qa_chain.invoke(input_dict)\n",
    "\n",
    "    validation_result = validator_chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"answer\": answer\n",
    "    }).strip()\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"validation\": validation_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example use inside your loop:\n",
    "for question in questions:\n",
    "    result = qa_with_validation(context_text, question)\n",
    "    print(f\"Q: {result['question']}\")\n",
    "    print(f\"A: {result['answer']}\")\n",
    "    print(f\"✅ VALID\\n\" if result['validation'] == \"VALID\" else f\"❌ INVALID\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
